{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting inputs and targets\n",
    "raw_csv_data=np.loadtxt('/Users/nagavedareddy/Downloads/Audiobooks_data.csv',delimiter=',')\n",
    "unscaled_inputs_all=raw_csv_data[:,1:-1]\n",
    "targets_all=raw_csv_data[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balancing the dataset\n",
    "num_one_targets=int(np.sum(targets_all))\n",
    "\n",
    "zero_targets_counter=0\n",
    "indices_to_remove=[]\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i]==0:\n",
    "        zero_targets_counter+=1\n",
    "        if zero_targets_counter>num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "unscaled_inputs_equal_priors=np.delete(unscaled_inputs_all,indices_to_remove,axis=0)\n",
    "targets_equal_priors=np.delete(targets_all,indices_to_remove,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the Inputs\n",
    "scaled_inputs=preprocessing.scale(unscaled_inputs_equal_priors)\n",
    "\n",
    "#Shuffling the data(We have o shuffle the data as we do batching the data)\n",
    "shuffled_indices=np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs=scaled_inputs[shuffled_indices]\n",
    "shuffled_targets=targets_equal_priors[shuffled_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train,validation and test\n",
    "\n",
    "samples_count=shuffled_inputs.shape[0]\n",
    "train_samples_count=int(0.8*samples_count)\n",
    "validation_samples_count=int(0.1*samples_count)\n",
    "test_samples_count=samples_count-train_samples_count-validation_samples_count\n",
    "\n",
    "train_inputs=shuffled_inputs[:train_samples_count]\n",
    "train_targets=shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs=shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets=shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs=shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets=shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the balance\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets)/train_samples_count)\n",
    "print(np.sum(validation_targets),validation_samples_count,np.sum(validation_targets)/validation_samples_count)\n",
    "print(np.sum(test_targets),test_samples_count,np.sum(test_targets)/test_samples_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving them to an tensor friendly format\n",
    "np.savez('Audiobooks_data_train',inputs=train_inputs,targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation',inputs=validation_inputs,targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test',inputs=test_inputs,targets=test_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for batching\n",
    "class Audiobooks_Data_Reader():\n",
    "    def __init__(self,dataset,batch_size=None):\n",
    "        npz=np.load('Audiobooks_data_{0}.npz'.format(dataset))\n",
    "        self.inputs,self.targets=npz['inputs'].astype(np.float),npz['targets'].astype(np.int)\n",
    "        if batch_size is None:\n",
    "            self.batch_size=self.inputs.shape[0]\n",
    "        else:\n",
    "            self.batch_size=batch_size\n",
    "        self.curr_batch=0\n",
    "        self.batch_count=self.inputs.shape[0]//self.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method that loads the next batch\n",
    "    def __next__(self):\n",
    "        if self.curr_batch >= self.batch_count:\n",
    "            self.curr_batch=0\n",
    "            raise StopIteration()\n",
    "\n",
    "        batch_slice=slice(self.curr_batch*self.batch_size,(self.curr_batch+1)*self.batch_size)\n",
    "        inputs_batch=self.inputs[batch_slice]\n",
    "        targets_batch=self.targets[batch_slice]\n",
    "        self.curr_batch+=1\n",
    "\n",
    "        # One-hot encode the targets. In this example it's a bit superfluous since we have a 0/1 column\n",
    "        classes_num=2\n",
    "        targets_one_hot=np.zeros((targets_batch.shape[0],classes_num))\n",
    "        targets_one_hot[range(targets_batch.shape[0]),targets_batch]=1\n",
    "        return  inputs_batch,targets_one_hot\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlining of the model\n",
    "input_size=10\n",
    "output_size=2\n",
    "hidden_layer_size=50\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs=tf.placeholder(tf.float32,[None,input_size])\n",
    "targets=tf.placeholder(tf.int32,[None,output_size])\n",
    "\n",
    "weights_1=tf.get_variable(\"weights_1\",[input_size,hidden_layer_size])\n",
    "biases_1=tf.get_variable(\"biases_1\",[hidden_layer_size])\n",
    "\n",
    "outputs_1=tf.nn.relu(tf.matmul(inputs,weights_1)+biases_1)\n",
    "\n",
    "weights_2=tf.get_variable(\"weights_2\",[hidden_layer_size,hidden_layer_size])\n",
    "biases_2=tf.get_variable(\"biases_2\",[hidden_layer_size])\n",
    "\n",
    "outputs_2=tf.nn.relu(tf.matmul(outputs_1,weights_2)+biases_2)\n",
    "\n",
    "weights_3=tf.get_variable(\"weights_3\",[hidden_layer_size,output_size])\n",
    "biases_3=tf.get_variable(\"biases_3\",[output_size])\n",
    "\n",
    "outputs=tf.matmul(outputs_2,weights_3)+biases_3\n",
    "\n",
    "loss=tf.nn.softmax_cross_entropy_with_logits(logits=outputs,labels=targets)\n",
    "mean_loss=tf.reduce_mean(loss)\n",
    "optimize=tf.train.AdamOptimizer(learning_rate=0.001).minimize(mean_loss)\n",
    "\n",
    "out_equals_target=tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(out_equals_target,tf.float32))\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "initializer=tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "\n",
    "batch_size=100\n",
    "\n",
    "max_epochs=50\n",
    "prev_validation_loss=9999999.\n",
    "\n",
    "train_data=Audiobooks_Data_Reader('train',batch_size)\n",
    "validation_data=Audiobooks_Data_Reader('validation')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the model\n",
    "for epoch_counter in range(max_epochs):\n",
    "    curr_epochs_loss=0\n",
    "    for input_batch,target_batch in train_data:\n",
    "        _, batch_loss=sess.run([optimize,mean_loss],feed_dict={inputs:input_batch,targets:target_batch})\n",
    "        curr_epochs_loss+=batch_loss\n",
    "\n",
    "    curr_epochs_loss/=train_data.batch_count\n",
    "    validation_loss=0.\n",
    "    validation_accuracy=0.\n",
    "    for input_batch,target_batch in validation_data:\n",
    "        validation_loss,validation_accuracy=sess.run([mean_loss,accuracy],feed_dict={inputs:input_batch,targets:target_batch})\n",
    "\n",
    "    print('Epoch : ' + str(epoch_counter + 1) + 'Training loss: ' + '{0:.3f}'.format(\n",
    "        curr_epochs_loss) + 'Validation Loss: ' + '{0:.3f}'.format(\n",
    "        validation_loss) + ' Validation Accuracy: ' + '{0:.2f}'.format(validation_accuracy * 100) + '%')\n",
    "    if validation_loss > prev_validation_loss:\n",
    "        break\n",
    "    prev_validation_loss=validation_loss\n",
    "\n",
    "print(\"End of the training\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "###\n",
    "test_data=Audiobooks_Data_Reader ('test')\n",
    "\n",
    "for input_batch,target_batch in test_data:\n",
    "    test_accuracy=sess.run([accuracy],feed_dict={inputs:input_batch,targets:target_batch})\n",
    "    test_accuracy_percent=test_accuracy[0]*100\n",
    "\n",
    "print(\"Test accuracy: \"+'{0:.2f}'.format(test_accuracy_percent)+'%')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
